#!/usr/bin/env python3
"""AI Server ä¸»ç¨‹åºå…¥å£"""

import sys
import os
import glob
import traceback
from datetime import datetime
import json
from dotenv import load_dotenv

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
if project_root not in sys.path:
    sys.path.insert(0, project_root)

# åŠ è½½.envæ–‡ä»¶
load_dotenv()

# å¯¼å…¥æ‰€æœ‰AIæ¨¡å—
from ai_core.tts.edge import EdgeTTS
from ai_core.asr.funasr_wrapper import FunASR
from ai_core.llm.chatglm import ChatGLM
from ai_core.audio.audio import DownlinkProcessor, UplinkProcessor

class TestSessionManager:
    """æµ‹è¯•ä¼šè¯ç®¡ç†å™¨ - è´Ÿè´£ä¿å­˜æµ‹è¯•è¾“å‡ºå’Œç»“æœ"""
    
    def __init__(self):
        """åˆå§‹åŒ–æµ‹è¯•ä¼šè¯"""
        self.session_time = datetime.now()
        self.timestamp = self.session_time.strftime("%Y%m%d_%H%M%S")
        self.test_results = {}
        self.created_folders = set()  # è®°å½•å·²åˆ›å»ºçš„caseæ–‡ä»¶å¤¹
        
        # ç¡®ä¿outputsç›®å½•å­˜åœ¨
        os.makedirs("outputs", exist_ok=True)
    
    def log_test_result(self, test_name, result_data):
        """è®°å½•æµ‹è¯•ç»“æœ"""
        self.test_results[test_name] = {
            'timestamp': datetime.now().isoformat(),
            'result': result_data
        }
        
    def get_case_path(self, case_name):
        """è·å–æŒ‡å®šcaseçš„è¾“å‡ºè·¯å¾„ï¼ˆæŒ‰éœ€åˆ›å»ºæ–‡ä»¶å¤¹ï¼‰"""
        path = f"outputs/{self.timestamp}/{case_name}"
        if case_name not in self.created_folders:
            os.makedirs(path, exist_ok=True)
            self.created_folders.add(case_name)
            print(f"ğŸ“ åˆ›å»ºæµ‹è¯•è¾“å‡ºæ–‡ä»¶å¤¹: {path}")
        return path
    
    def save_session_summary(self):
        """ä¿å­˜æµ‹è¯•ä¼šè¯æ€»ç»“"""
        summary = {
            'session_info': {
                'start_time': self.session_time.isoformat(),
                'end_time': datetime.now().isoformat(),
                'timestamp': self.timestamp,
                'created_cases': list(self.created_folders)
            },
            'test_results': self.test_results
        }
        
        summary_file = f"outputs/{self.timestamp}/test_summary.json"
        os.makedirs(f"outputs/{self.timestamp}", exist_ok=True)
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        
        print(f"\nğŸ“‹ æµ‹è¯•ä¼šè¯æ€»ç»“å·²ä¿å­˜: {summary_file}")
        return summary_file

# å…¨å±€æµ‹è¯•ä¼šè¯ç®¡ç†å™¨
test_session = TestSessionManager()

def get_performance_tips(inference_time, has_cuda):
    """ç”Ÿæˆæ€§èƒ½ä¼˜åŒ–å»ºè®®"""
    tips = []
    
    # GPUç›¸å…³å»ºè®®
    if not has_cuda:
        tips.append("ï¿½ **GPUåŠ é€Ÿé€‰é¡¹**:")
        
        # Intel GPU ä¼˜åŒ–å»ºè®®
        tips.append("ğŸ”¹ **Intel Irisæ˜¾å¡ç”¨æˆ·**:")
        tips.append("   1. Intel XPUæ”¯æŒ (å®éªŒæ€§ï¼Œæå‡æœ‰é™ ~20-30%):")
        tips.append("      pip install intel-extension-for-pytorch")
        tips.append("      pip install torch==2.1.0 torchvision==0.16.0 torchaudio==2.1.0 --index-url https://download.pytorch.org/whl/cpu")
        tips.append("   âš ï¸  æ³¨æ„: Intel GPUå¯¹AIæ¨¡å‹æ”¯æŒæœ‰é™ï¼Œæ•ˆæœä¸å¦‚NVIDIA GPU")
        
        tips.append("ğŸ”¹ **NVIDIA GPUç”¨æˆ· (æœ€ä½³é€‰æ‹©)**:")
        tips.append("   pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121")
        tips.append("   ğŸš€ æ€§èƒ½æå‡: 5-10å€ (å¼ºçƒˆæ¨è)")
        
        tips.append("ğŸ”¹ **CPUä¼˜åŒ– (å½“å‰æ–¹æ¡ˆ)**:")
        tips.append("   - ç¡®ä¿ä½¿ç”¨æ‰€æœ‰CPUæ ¸å¿ƒ")
        tips.append("   - å…³é—­å…¶ä»–å ç”¨CPUçš„ç¨‹åº")
        tips.append("   - ä½¿ç”¨æ›´çŸ­çš„éŸ³é¢‘ç‰‡æ®µ")
    
    # é€Ÿåº¦åˆ†çº§å»ºè®®  
    if inference_time > 8.0:
        tips.append("ğŸŒ **æ¨ç†å¾ˆæ…¢** (>8ç§’):")
        tips.append("   - Intel Iris: é¢„è®¡æå‡20-30% â†’ çº¦6-7ç§’")
        tips.append("   - NVIDIA GPU: é¢„è®¡æå‡500-1000% â†’ çº¦1-2ç§’")
        tips.append("   - éŸ³é¢‘åˆ†å‰²: <30ç§’ç‰‡æ®µå¤„ç†")
    elif inference_time > 5.0:
        tips.append("ğŸŒ **æ¨ç†è¾ƒæ…¢** (5-8ç§’):")
        tips.append("   - Intel Iris: å¯å°è¯•ï¼Œä½†æå‡æœ‰é™")
        tips.append("   - å»ºè®®ä½¿ç”¨ç‹¬ç«‹NVIDIAæ˜¾å¡")
    elif inference_time > 2.0:
        tips.append("âš¡ **å¯ä¼˜åŒ–** (2-5ç§’):")
        tips.append("   - æ€§èƒ½å·²è¾ƒå¥½ï¼ŒGPUä¼˜åŒ–å¯é€‰")
    elif inference_time < 1.0:
        tips.append("ğŸ‰ **æ€§èƒ½ä¼˜ç§€** (<1ç§’)!")
        
    # Intel Iris ä¸“ç”¨å»ºè®®
    tips.append("ğŸ”· **Intel Irisæ˜¾å¡è¯´æ˜**:")
    tips.append("   - Intel GPUä¸»è¦ç”¨äºè§†é¢‘ç¼–è§£ç ï¼ŒAIæ¨ç†èƒ½åŠ›æœ‰é™")
    tips.append("   - FunASRç­‰è¯­éŸ³æ¨¡å‹å¯¹Intel GPUæ”¯æŒä¸å®Œå–„")
    tips.append("   - é¢„æœŸæ€§èƒ½æå‡: 20-30% (ç›¸æ¯”çº¯CPU)")
    tips.append("   - ä»å»ºè®®ä½¿ç”¨NVIDIA GPUè·å¾—æœ€ä½³æ€§èƒ½")
        
    # é€šç”¨ä¼˜åŒ–å»ºè®®
    tips.append("ğŸ“Š **é€šç”¨ä¼˜åŒ–**:")
    tips.append("   - æ‰¹é‡å¤„ç†å¤šä¸ªæ–‡ä»¶")
    tips.append("   - ä½¿ç”¨16kHzé‡‡æ ·ç‡éŸ³é¢‘")
    tips.append("   - ç›‘æ§CPU/GPUä½¿ç”¨ç‡")
    
    return tips

def main():
    """ä¸»ç¨‹åºå…¥å£"""
    print("ğŸš€ AI Server")
    print("1. EdgeTTS æ¼”ç¤º")  
    print("2. FunASR æ¼”ç¤º")
    print("3. ChatGLM æ¼”ç¤º")
    print("4. Audio å¤„ç†æ¼”ç¤º")
    print("5. ç»¼åˆæ¼”ç¤º (Audio+ASR+LLM+TTS)")
    print("0. é€€å‡º")
    
    try:
        choice = input("\né€‰æ‹©åŠŸèƒ½: ").strip() or "1"
        
        if choice == "1":
            test_edge_tts()
        elif choice == "2": 
            test_funasr()
        elif choice == "3":
            test_chatglm()
        elif choice == "4":
            test_audio_processing()
        elif choice == "5":
            test_comprehensive_demo()
        elif choice == "0":
            print("é€€å‡º")
        else:
            print("æ— æ•ˆé€‰æ‹©")
            
    except Exception as e:
        print(f"è¿è¡Œå¤±è´¥: {e}")

def test_edge_tts():
    """EdgeTTSæµ‹è¯•"""
    try:
        print("ğŸ¤ EdgeTTS æµ‹è¯•")
        print("=" * 40)
        
        tts = EdgeTTS.get_instance()
        
        # ä½¿ç”¨EdgeTTS caseæ–‡ä»¶å¤¹
        tts_folder = test_session.get_case_path("EdgeTTS")
        
        text = input("ğŸ¤ è¯·è¾“å…¥è¦åˆæˆçš„æ–‡å­— (ç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤): ").strip()
        if not text:
            text = "ä½ å¥½ï¼Œè¿™æ˜¯EdgeTTSè¯­éŸ³åˆæˆæµ‹è¯•"
        
        # ä¿å­˜åˆ°ä¼šè¯æ–‡ä»¶å¤¹
        output_filename = f"edgetts_test_{datetime.now().strftime('%H%M%S')}.mp3"
        output_path = os.path.join(tts_folder, output_filename)
        
        # EdgeTTSç°åœ¨æ”¯æŒå®Œæ•´è·¯å¾„
        result = tts.text_to_speech(text, output_path)
        
        test_result = {
            'test_type': 'EdgeTTS',
            'input_text': text,
            'output_file': result,
            'status': 'success' if result else 'failed'
        }
        
        if result:
            print(f"âœ… TTSæˆåŠŸ: {result}")
            print(f"ğŸ“ æ–‡ä»¶ä¿å­˜è‡³: {result}")
        else:
            print("âŒ TTSå¤±è´¥")
            
        # è®°å½•æµ‹è¯•ç»“æœ
        test_session.log_test_result('EdgeTTS', test_result)
            
    except Exception as e:
        print(f"âŒ TTSå¤±è´¥: {e}")
        test_session.log_test_result('EdgeTTS', {
            'test_type': 'EdgeTTS',
            'status': 'error',
            'error': str(e)
        })

def test_funasr():
    """FunASRæµ‹è¯•"""
    import time
    import torch
    
    try:
        print("ğŸ¤ FunASR è¯­éŸ³è¯†åˆ«æµ‹è¯•")
        print("=" * 40)
        
        # æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯
        print(f"ğŸ–¥ï¸  è®¾å¤‡ä¿¡æ¯:")
        print(f"   CPUæ ¸å¿ƒæ•°: {os.cpu_count()}")
        print(f"   CUDAå¯ç”¨: {'âœ…' if torch.cuda.is_available() else 'âŒ'}")
        if torch.cuda.is_available():
            print(f"   GPUè®¾å¤‡: {torch.cuda.get_device_name()}")
            print(f"   GPUå†…å­˜: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB")
        
        # åˆå§‹åŒ–ASRï¼ˆæµ‹é‡åˆå§‹åŒ–æ—¶é—´ï¼‰
        print(f"\nâ±ï¸  æ¨¡å‹åŠ è½½ä¸­...")
        start_time = time.time()
        asr = FunASR.get_instance()
        init_time = time.time() - start_time
        print(f"   åˆå§‹åŒ–è€—æ—¶: {init_time:.2f}ç§’")
        
        # æŸ¥æ‰¾æµ‹è¯•éŸ³é¢‘æ–‡ä»¶ï¼ˆä¼˜å…ˆä»å½“å‰ä¼šè¯çš„EdgeTTSï¼Œç„¶åæ˜¯æ‰€æœ‰æ—¶é—´æˆ³æ–‡ä»¶å¤¹ï¼‰
        session_audio_files = glob.glob(f"outputs/{test_session.timestamp}/EdgeTTS/*.mp3")
        general_audio_files = glob.glob("outputs/*/EdgeTTS/*.mp3")
        
        audio_files = session_audio_files + general_audio_files
        
        if not audio_files:
            print("âŒ æœªæ‰¾åˆ°æµ‹è¯•éŸ³é¢‘æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡ŒEdgeTTSæ¼”ç¤º")
            return
            
        audio_file = audio_files[0]
        # è·å–éŸ³é¢‘æ–‡ä»¶ä¿¡æ¯
        file_size = os.path.getsize(audio_file) / 1024
        print(f"\nğŸ“ éŸ³é¢‘æ–‡ä»¶: {os.path.basename(audio_file)}")
        print(f"   æ–‡ä»¶å¤§å°: {file_size:.1f} KB")
        
        # æ‰§è¡ŒASRè¯†åˆ«ï¼ˆæµ‹é‡æ¨ç†æ—¶é—´ï¼‰
        print(f"\nğŸ”„ å¼€å§‹è¯†åˆ«...")
        start_time = time.time()
        result = asr.transcribe_file(audio_file)
        inference_time = time.time() - start_time
        
        print(f"âœ… è¯†åˆ«å®Œæˆ!")
        print(f"ğŸ¯ è¯†åˆ«ç»“æœ: {result}")
        print(f"â±ï¸  æ¨ç†è€—æ—¶: {inference_time:.2f}ç§’")
        
        # ä¿å­˜ASRç»“æœ
        asr_folder = test_session.get_case_path("FunASR")
        
        result_file = os.path.join(asr_folder, "recognition_result.txt")
        with open(result_file, "w", encoding="utf-8") as f:
            f.write(f"FunASRè¯­éŸ³è¯†åˆ«ç»“æœ\n")
            f.write(f"=" * 30 + "\n")
            f.write(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"éŸ³é¢‘æ–‡ä»¶: {audio_file}\n")
            f.write(f"æ–‡ä»¶å¤§å°: {file_size:.1f} KB\n")
            f.write(f"è¯†åˆ«ç»“æœ: {result}\n")
            f.write(f"åˆå§‹åŒ–è€—æ—¶: {init_time:.2f}ç§’\n")
            f.write(f"æ¨ç†è€—æ—¶: {inference_time:.2f}ç§’\n")
            if result:
                chars_per_sec = len(result) / inference_time if inference_time > 0 else 0
                f.write(f"æ€§èƒ½æŒ‡æ ‡: {chars_per_sec:.1f} å­—ç¬¦/ç§’\n")
        
        print(f"ğŸ“„ è¯†åˆ«ç»“æœå·²ä¿å­˜åˆ°: {result_file}")
        
        # è®¡ç®—æ€§èƒ½æŒ‡æ ‡
        if result:
            chars_per_sec = len(result) / inference_time if inference_time > 0 else 0
            print(f"ğŸ“Š æ€§èƒ½æŒ‡æ ‡: {chars_per_sec:.1f} å­—ç¬¦/ç§’")
        
        # è¯¦ç»†çš„æ€§èƒ½åˆ†æå’Œå»ºè®®
        print(f"\nï¿½ æ€§èƒ½åˆ†ææŠ¥å‘Š:")
        print(f"   ğŸ“ æ€»è€—æ—¶: {init_time + inference_time:.2f}ç§’ (åˆå§‹åŒ–: {init_time:.2f}s + æ¨ç†: {inference_time:.2f}s)")
        
        # è·å–æ€§èƒ½ç­‰çº§
        if inference_time < 1.0:
            level = "ğŸ‰ ä¼˜ç§€"
        elif inference_time < 2.0:
            level = "âœ… è‰¯å¥½"  
        elif inference_time < 5.0:
            level = "âš¡ ä¸€èˆ¬"
        else:
            level = "ğŸŒ è¾ƒæ…¢"
            
        print(f"   ğŸ† æ€§èƒ½ç­‰çº§: {level}")
        
        # æ˜¾ç¤ºä¼˜åŒ–å»ºè®®
        print(f"\nğŸ’¡ æ€§èƒ½ä¼˜åŒ–å»ºè®®:")
        tips = get_performance_tips(inference_time, torch.cuda.is_available())
        for tip in tips:
            print(f"   {tip}")
        
    except Exception as e:
        print(f"âŒ ASRå¤±è´¥: {e}")
        traceback.print_exc()

def test_chatglm():
    """ChatGLMæµ‹è¯•"""
    try:
        # æ£€æŸ¥APIå¯†é’¥
        api_key = os.getenv('ZHIPU_API_KEY')
        if not api_key:
            print("âŒ æœªé…ç½®ZHIPU_API_KEYç¯å¢ƒå˜é‡")
            print("ğŸ’¡ è¯·è®¾ç½®APIå¯†é’¥: export ZHIPU_API_KEY=your_api_key")
            return
        
        chatglm = ChatGLM.get_instance(api_key)
        
        # ç®€å•å¯¹è¯æµ‹è¯•
        user_input = input("ğŸ’¬ è¯·è¾“å…¥é—®é¢˜ (ç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤): ").strip()
        if not user_input:
            user_input = "ä½ å¥½ï¼Œè¯·ç®€å•ä»‹ç»ä¸€ä¸‹è‡ªå·±"
        
        print("ğŸ¤– ChatGLMæ­£åœ¨æ€è€ƒ...")
        response = chatglm.generate_response(user_input)
        print(f"ğŸ¤– å›å¤: {response}")
        
        # ä¿å­˜ChatGLMå¯¹è¯ç»“æœ
        chatglm_folder = test_session.get_case_path("ChatGLM")
        
        chat_file = os.path.join(chatglm_folder, "conversation.txt")
        with open(chat_file, "w", encoding="utf-8") as f:
            f.write(f"ChatGLMå¯¹è¯è®°å½•\n")
            f.write(f"=" * 30 + "\n")
            f.write(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"ç”¨æˆ·é—®é¢˜: {user_input}\n")
            f.write(f"AIå›å¤: {response}\n")
        
        print(f"ğŸ“„ å¯¹è¯è®°å½•å·²ä¿å­˜åˆ°: {chat_file}")
        
    except Exception as e:
        print(f"ChatGLMå¤±è´¥: {e}")

def test_audio_processing():
    """Audioå¤„ç†æ¼”ç¤º"""
    try:
        
        print("ğŸµ Audio å¤„ç†æ¼”ç¤º")
        print("=" * 40)
        
        # æŸ¥æ‰¾éŸ³é¢‘æ–‡ä»¶ï¼ˆä»æ‰€æœ‰æ—¶é—´æˆ³æ–‡ä»¶å¤¹çš„EdgeTTSå­æ–‡ä»¶å¤¹ä¸­æŸ¥æ‰¾ï¼‰
        audio_files = glob.glob("outputs/*/EdgeTTS/*.mp3")
        if not audio_files:
            print("âŒ æœªæ‰¾åˆ°éŸ³é¢‘æ–‡ä»¶ï¼Œè¯·å…ˆè¿è¡ŒEdgeTTSæ¼”ç¤ºç”ŸæˆéŸ³é¢‘")
            return
        
        input_file = audio_files[0]
        print(f"ğŸ“ è¾“å…¥æ–‡ä»¶: {input_file}")
        
        # ä¸‹è¡Œå¤„ç†æ¼”ç¤º (TTS -> Opus)
        print("\nğŸ“¤ ä¸‹è¡Œå¤„ç† (TTSéŸ³é¢‘ -> Opusæ ¼å¼)")
        downlink = DownlinkProcessor(preset="balanced")
        opus_data = downlink.process_audio(input_file, output_format="bytes")
        print(f"   Opusæ•°æ®å¤§å°: {len(opus_data):,} bytes")
        
        # ä¿å­˜éŸ³é¢‘å¤„ç†ç»“æœ - å…ˆè·å–caseæ–‡ä»¶å¤¹
        audio_folder = test_session.get_case_path("Audio")
        
        # ä¸Šè¡Œå¤„ç†æ¼”ç¤º (Opus -> WAV) - ç›´æ¥ä¿å­˜åˆ°caseæ–‡ä»¶å¤¹
        print("\nğŸ“¥ ä¸Šè¡Œå¤„ç† (Opusæ•°æ® -> WAVæ ¼å¼)")
        uplink = UplinkProcessor(preset="general")
        session_wav_file = os.path.join(audio_folder, "decoded.wav")
        
        # ç¡®ä¿opus_dataæ˜¯bytesç±»å‹
        if isinstance(opus_data, bytes):
            output_file = uplink.decode_opus(opus_data, output_format="file", output_path=session_wav_file)
        else:
            print("âŒ Opusæ•°æ®ç±»å‹é”™è¯¯")
            return
        print(f"   è¾“å‡ºæ–‡ä»¶: {output_file}")
        
        # æ˜¾ç¤ºæ–‡ä»¶å¤§å°å¯¹æ¯”  
        original_size = os.path.getsize(input_file)
        opus_size = len(opus_data)
        # ç¡®ä¿output_fileæ˜¯å­—ç¬¦ä¸²è·¯å¾„
        if isinstance(output_file, str):
            decoded_size = os.path.getsize(output_file)
        else:
            decoded_size = 0
        
        print(f"\nğŸ“Š æ–‡ä»¶å¤§å°å¯¹æ¯”:")
        print(f"   åŸå§‹MP3: {original_size:,} bytes")
        print(f"   Opusç¼–ç : {opus_size:,} bytes (å‹ç¼© {(1-opus_size/original_size)*100:.1f}%)")
        print(f"   è§£ç WAV: {decoded_size:,} bytes")
        
        # ä¿å­˜å¤„ç†æŠ¥å‘Š
        report_file = os.path.join(audio_folder, "processing_report.txt")
        with open(report_file, "w", encoding="utf-8") as f:
            f.write(f"éŸ³é¢‘å¤„ç†æµ‹è¯•æŠ¥å‘Š\n")
            f.write(f"=" * 30 + "\n")
            f.write(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"è¾“å…¥æ–‡ä»¶: {input_file}\n")
            f.write(f"è¾“å‡ºæ–‡ä»¶: {output_file}\n")
            f.write(f"åŸå§‹MP3å¤§å°: {original_size:,} bytes\n")
            f.write(f"Opusç¼–ç å¤§å°: {opus_size:,} bytes\n")
            f.write(f"å‹ç¼©æ¯”ä¾‹: {(1-opus_size/original_size)*100:.1f}%\n")
            f.write(f"è§£ç WAVå¤§å°: {decoded_size:,} bytes\n")
        
        # ä¿å­˜Opusæ•°æ®
        opus_file = os.path.join(audio_folder, "encoded.opus")
        with open(opus_file, "wb") as f:
            f.write(opus_data)
            
        print(f"ğŸ“„ å¤„ç†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        print(f"ğŸ“„ ç¼–ç æ–‡ä»¶å·²ä¿å­˜åˆ°: {opus_file}")
        
    except Exception as e:
        print(f"Audioå¤„ç†å¤±è´¥: {e}")

def test_comprehensive_demo():
    """ç»¼åˆæ¼”ç¤º: Audio+ASR+LLM+TTS"""
    try:
        import os
        print("ğŸŒŸ AI Server ç»¼åˆæ¼”ç¤º")
        print("=" * 50)
        print("æµç¨‹: ç”¨æˆ·è¾“å…¥ -> TTS -> Audioå¤„ç† -> ASR -> LLM -> TTS")
        
        # æ£€æŸ¥APIå¯†é’¥
        api_key = os.getenv('ZHIPU_API_KEY')
        if not api_key:
            print("âŒ éœ€è¦ZHIPU_API_KEYç¯å¢ƒå˜é‡æ‰èƒ½è¿è¡Œç»¼åˆæ¼”ç¤º")
            return
        
        # 1. ç”¨æˆ·è¾“å…¥
        user_text = input("ğŸ’¬ è¯·è¾“å…¥ä¸€ä¸ªé—®é¢˜ (ç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤): ").strip()
        if not user_text:
            user_text = "ä»€ä¹ˆæ˜¯äººå·¥æ™ºèƒ½?"
        
        print(f"\nğŸ¯ ç”¨æˆ·é—®é¢˜: {user_text}")
        
        # 2. TTS - å°†ç”¨æˆ·é—®é¢˜è½¬ä¸ºè¯­éŸ³
        print("\nğŸ¤ æ­¥éª¤1: æ–‡å­—è½¬è¯­éŸ³ (TTS)")
        tts = EdgeTTS.get_instance()
        # è·å–ç»¼åˆæ¼”ç¤ºçš„è¾“å‡ºæ–‡ä»¶å¤¹
        comp_folder = test_session.get_case_path("Comprehensive")
        user_audio_path = os.path.join(comp_folder, "user_question.mp3")
        tts_result = tts.text_to_speech(user_text, user_audio_path)
        if not tts_result:
            print("âŒ TTSå¤±è´¥")
            return
        audio_path = user_audio_path
        print(f"   âœ… ç”Ÿæˆè¯­éŸ³: {audio_path}")
        
        # 3. Audioå¤„ç† - æ¨¡æ‹ŸIoTè®¾å¤‡ä¼ è¾“
        print("\nğŸ“¡ æ­¥éª¤2: éŸ³é¢‘ç¼–ç ä¼ è¾“ (Audio Processing)")
        
        # ä¸‹è¡Œ: ç¼–ç ä¸ºOpus
        downlink = DownlinkProcessor(preset="low_latency")
        opus_data = downlink.process_audio(audio_path, output_format="bytes")
        print(f"   ğŸ“¤ Opusç¼–ç : {len(opus_data):,} bytes")
        
        # ä¸Šè¡Œ: è§£ç ä¸ºWAVä¾›ASRä½¿ç”¨
        uplink = UplinkProcessor(preset="general")
        # ä¿å­˜åˆ°Comprehensiveæ–‡ä»¶å¤¹ä¸­
        asr_audio_path = os.path.join(comp_folder, "for_asr.wav")
        # ç¡®ä¿opus_dataæ˜¯bytesç±»å‹
        if isinstance(opus_data, bytes):
            uplink.decode_to_file(opus_data, asr_audio_path)
        else:
            print("âŒ Opusæ•°æ®ç±»å‹é”™è¯¯")
            return
        print(f"   ğŸ“¥ è§£ç éŸ³é¢‘: {asr_audio_path}")
        
        # 4. ASR - è¯­éŸ³è¯†åˆ«
        print("\nğŸ¤ æ­¥éª¤3: è¯­éŸ³è¯†åˆ« (ASR)")
        import time
        asr = FunASR.get_instance()
        
        print("   â±ï¸ å¼€å§‹è¯†åˆ«...")
        start_time = time.time()
        recognized_text = asr.transcribe_file(asr_audio_path)
        asr_time = time.time() - start_time
        
        if not recognized_text:
            print("âŒ ASRå¤±è´¥")
            return
        print(f"   ğŸ¯ è¯†åˆ«ç»“æœ: {recognized_text}")
        print(f"   âš¡ ASRè€—æ—¶: {asr_time:.2f}ç§’")
        
        # 5. LLM - ç”Ÿæˆå›ç­”
        print("\nğŸ¤– æ­¥éª¤4: AIç”Ÿæˆå›ç­” (LLM)")
        chatglm = ChatGLM.get_instance(api_key)
        ai_response = chatglm.generate_response(recognized_text)
        print(f"   ğŸ’¡ AIå›ç­”: {ai_response}")
        
        # 6. TTS - å°†AIå›ç­”è½¬ä¸ºè¯­éŸ³
        print("\nğŸ”Š æ­¥éª¤5: å›ç­”è½¬è¯­éŸ³ (TTS)")
        ai_audio_path = os.path.join(comp_folder, "ai_response.mp3") 
        tts_result = tts.text_to_speech(ai_response, ai_audio_path)
        if tts_result:
            print(f"   âœ… å›ç­”è¯­éŸ³: {tts_result}")
        
        # ä¿å­˜ç»¼åˆæŠ¥å‘Š
        demo_report_file = os.path.join(comp_folder, "demo_report.txt")
        with open(demo_report_file, "w", encoding="utf-8") as f:
            f.write(f"AI Server ç»¼åˆæ¼”ç¤ºæŠ¥å‘Š\n")
            f.write(f"=" * 40 + "\n")
            f.write(f"æµ‹è¯•æ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
            f.write(f"æµç¨‹: ç”¨æˆ·è¾“å…¥ -> TTS -> Audioå¤„ç† -> ASR -> LLM -> TTS\n\n")
            f.write(f"1. ç”¨æˆ·é—®é¢˜: {user_text}\n")
            f.write(f"2. TTSç”Ÿæˆè¯­éŸ³: {audio_path}\n")
            f.write(f"3. Opusç¼–ç å¤§å°: {len(opus_data):,} bytes\n")
            f.write(f"4. è§£ç éŸ³é¢‘: {asr_audio_path}\n")
            f.write(f"5. ASRè¯†åˆ«ç»“æœ: {recognized_text}\n")
            f.write(f"6. ASRè€—æ—¶: {asr_time:.2f}ç§’\n")
            f.write(f"7. AIå›ç­”: {ai_response}\n")
            f.write(f"8. å›ç­”è¯­éŸ³: {tts_result}\n")
        
        # æ–‡ä»¶å·²ç›´æ¥ç”Ÿæˆåˆ°æ­£ç¡®ä½ç½®ï¼Œæ— éœ€å¤åˆ¶
        
        print("\nğŸ‰ ç»¼åˆæ¼”ç¤ºå®Œæˆ!")
        print(f"ğŸ“„ æ¼”ç¤ºæŠ¥å‘Šå·²ä¿å­˜åˆ°: {demo_report_file}")
        print(f"ğŸ“‚ æ‰€æœ‰è¾“å‡ºæ–‡ä»¶ä¿å­˜åœ¨: {comp_folder}/")
        
    except Exception as e:
        print(f"ç»¼åˆæ¼”ç¤ºå¤±è´¥: {e}")
        traceback.print_exc()

if __name__ == "__main__":
    main()